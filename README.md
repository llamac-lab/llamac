# llamac

[![Build (CUDA - no GPU)](https://github.com/llamac-lab/llamac/actions/workflows/cuda-build.yml/badge.svg)](https://github.com/llamac-lab/llamac/actions/workflows/cuda-build.yml)

**llamac-lab** is a pure C runtime for LLaMA-based models, built for tiny devices, embedded environments, and maximum portability.

Think [`llama.cpp`](https://github.com/ggerganov/llama.cpp), but:
- Flattened into C
- Optimized for small memory
- Easy to integrate with any stack (Rust, Python, etc.)
- Born for the edge

note: work in progress, not a functioning anything yet :)
